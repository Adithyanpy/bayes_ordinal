import pymc as pm
import pytensor.tensor as pt
from typing import Union
import numpy as np

def partial_odds_model(
    y: Union[np.ndarray, list[int]],
    X: np.ndarray,
    K: int | None = None,
    priors: dict | None = None,
    group_idx: np.ndarray | None = None,
    n_groups: int | None = None,
    model_name: str = "partial_odds_model",
) -> pm.Model:
    """
    Constructs a partial-odds ordinal regression model using adjacent-category formulation.

    This model uses stick-breaking to convert latent utilities into category probabilities,
    allowing the effect of predictors to vary by category.

    Parameters
    ----------
    y : array-like of shape (n,)
        Ordinal response variable encoded as integers from 0 to K−1.
    X : np.ndarray of shape (n, p)
        Covariate matrix (features).
    K : int, optional
        Number of ordinal categories. If None, inferred from unique values in y.
    priors : dict, optional
        Dictionary of prior hyperparameters. Keys include:
            - "gamma_mu", "gamma_sigma" : mean and std for category-specific intercepts
            - "beta_mu", "beta_sigma"   : mean and std for slope coefficients
            - "u_sigma"                : std for varying group intercepts (if used)
    group_idx : np.ndarray of shape (n,), optional
        Group index for hierarchical intercepts (integer codes).
    n_groups : int, optional
        Number of groups (used with group_idx).
    model_name : str, default="partial_odds_model"
        Name for the PyMC model object.

    Returns
    -------
    model : pm.Model
        A PyMC model object ready for MCMC sampling.

    Notes
    -----
    Stick-breaking formulation generalizes multinomial logistic regression.
    Suitable for modeling non-proportional odds across categories.

    Examples
    --------
    >>> model = partial_odds_model(y, X, K=4)
    >>> idata = pm.sample(model=model)
    """
    
    # Infer K if not provided
    if K is None:
        K = len(np.unique(y))
    
    priors      = priors or {}
    mu_g        = priors.get("gamma_mu", 0.0)
    sigma_g     = priors.get("gamma_sigma", 5.0)
    mu_b        = priors.get("beta_mu", 0.0)
    sigma_b     = priors.get("beta_sigma", 5.0)
    u_sigma_pr  = priors.get("u_sigma", 1.0)

    with pm.Model(name=model_name) as model:
        # 1) adjacent‐category intercepts
        gamma = pm.Normal("gamma", mu=mu_g, sigma=sigma_g, shape=K-1)

        # 2) fixed slopes
        beta  = pm.Normal("beta",  mu=mu_b, sigma=sigma_b, shape=X.shape[1])

        # 3) optional non‐centered varying intercepts
        if group_idx is not None and n_groups is not None:
            u_sigma  = pm.HalfNormal("u_sigma", sigma=u_sigma_pr)
            u_offset = pm.Normal("u_offset", mu=0.0, sigma=1.0, shape=n_groups)
            u        = pm.Deterministic("u", u_offset * u_sigma)
            u_g      = u[group_idx][:, None]
        else:
            u_g = 0

        # 4) build η matrix (n × (K−1))
        η = X @ beta
        η = η[:, None] + gamma
        η = η + u_g

        # 5) stick‐breaking to get category probabilities
        θ   = pm.math.sigmoid(η)
        rem = pt.ones_like(θ[:, :1])
        ps  = []
        for j in range(K-1):
            pj = rem * θ[:, j : j+1]
            ps.append(pj)
            rem = rem * (1 - θ[:, j : j+1])
        ps.append(rem)
        p = pt.concatenate(ps, axis=1)

        # 6) likelihood
        pm.Categorical("y_obs", p=p, observed=y)

        # ─── default initvals for smoke-test fallback ─────────────────────────
        initvals: dict = {
            "gamma": np.linspace(-1.0, 1.0, num=K-1),
            "beta":  np.zeros(X.shape[1]),
        }
        if group_idx is not None and n_groups is not None:
            initvals["u_offset"] = np.zeros(n_groups)
            initvals["u_sigma"]  = 1.0

        model._default_initvals = initvals

    return model
