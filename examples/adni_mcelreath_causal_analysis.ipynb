{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADNI Alzheimer's Disease Causal Analysis\n",
    "### Following McElreath's Statistical Rethinking Methodology\n",
    "\n",
    "This notebook implements Richard McElreath's approach to statistical modeling for causal inference, applied to Alzheimer's disease progression using the `bayes_ordinal` package.\n",
    "\n",
    "## McElreath's Modeling Workflow:\n",
    "\n",
    "1. ** The Data Story** - Understanding how data arises\n",
    "2. ** Scientific Question** - What do we want to know?\n",
    "3. ** Causal Diagram (DAG)** - Identifying confounders and colliders\n",
    "4. ** Statistical Model** - Translating causality into math\n",
    "5. ** Prior Predictive Simulation** - Checking model assumptions\n",
    "6. ** Model Fitting** - Learning from data\n",
    "7. ** Posterior Validation** - Checking model quality\n",
    "8. ** Counterfactual Reasoning** - Answering causal questions\n",
    "\n",
    "---\n",
    "\n",
    "> *\"The goal is not to test a null hypothesis, but to estimate the causal effect of interventions on outcomes, while properly accounting for confounders.\"* - Richard McElreath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Packages and Data Generation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import arviz as az\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For DAG visualization (McElreath style)\n",
    "import networkx as nx\n",
    "from matplotlib.patches import FancyBboxPatch\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Import bayes_ordinal package\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import bayes_ordinal as bo\n",
    "\n",
    "# Set plotting style (McElreath prefers clean, readable plots)\n",
    "plt.style.use('default')\n",
    "sns.set_palette('colorblind')\n",
    "az.style.use('arviz-whitegrid')\n",
    "\n",
    "print(\"ðŸ§  ADNI Alzheimer's Causal Analysis\")\n",
    "print(\" Following McElreath's Statistical Rethinking methodology\")\n",
    "print(\" Using bayes_ordinal for ordinal causal inference\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: The Data Story \n",
    "\n",
    "**McElreath's Principle:** *\"Before we can analyze data, we need to understand how it could have arisen.\"*\n",
    "\n",
    "### The Alzheimer's Disease Data Generation Process:\n",
    "\n",
    "**Fundamental Variables (Exogenous):**\n",
    "- **Age** â†’ Natural aging process, affects everything\n",
    "- **Education** â†’ Early life factor, protective against cognitive decline\n",
    "- **APOE4 Gene** â†’ Genetic variant, increases Alzheimer's risk\n",
    "\n",
    "**Biological Pathways:**\n",
    "- **Age** â†’ Increases protein accumulation and brain atrophy\n",
    "- **APOE4** â†’ Accelerates amyloid and tau pathology  \n",
    "- **Education** â†’ Builds cognitive reserve, delays clinical symptoms\n",
    "\n",
    "**Pathological Markers:**\n",
    "- **Amyloid Beta** â† Age + APOE4 + individual variation\n",
    "- **TAU Protein** â† Age + APOE4 + Amyloid + individual variation\n",
    "- **Hippocampal Volume** â† Age + TAU + Amyloid + Education (protective)\n",
    "\n",
    "**Clinical Outcome:**\n",
    "- **Cognitive Status** â† All pathological markers + Education (protective) + Age + individual variation\n",
    "\n",
    "### Key Causal Questions:\n",
    "1. What is the **direct effect** of each biomarker on cognitive decline?\n",
    "2. How much does **education** protect against pathology?\n",
    "3. What are the **indirect effects** through biological pathways?\n",
    "4. Can we estimate **intervention effects** (e.g., reducing TAU)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Causal Diagram Construction (DAG)\n",
    "# Following McElreath: \"Draw your assumptions before you draw conclusions\"\n",
    "\n",
    "def create_alzheimers_dag():\n",
    "    \"\"\"Create a DAG for Alzheimer's disease following McElreath's approach\"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 10))\n",
    "    \n",
    "    # Define node positions (McElreath likes clean, hierarchical layouts)\n",
    "    pos = {\n",
    "        'Age': (2, 4),\n",
    "        'Education': (0, 4), \n",
    "        'APOE4': (4, 4),\n",
    "        'Amyloid': (1, 2.5),\n",
    "        'TAU': (3, 2.5),\n",
    "        'Hippocampus': (2, 1),\n",
    "        'Cognitive_Status': (2, -0.5)\n",
    "    }\n",
    "    \n",
    "    # Create networkx graph\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(pos.keys())\n",
    "    \n",
    "    # Add edges based on our causal story\n",
    "    edges = [\n",
    "        # Fundamental causes\n",
    "        ('Age', 'Amyloid'), ('Age', 'TAU'), ('Age', 'Hippocampus'), ('Age', 'Cognitive_Status'),\n",
    "        ('APOE4', 'Amyloid'), ('APOE4', 'TAU'),\n",
    "        ('Education', 'Hippocampus'), ('Education', 'Cognitive_Status'),\n",
    "        \n",
    "        # Biological pathway\n",
    "        ('Amyloid', 'TAU'), ('TAU', 'Hippocampus'),\n",
    "        \n",
    "        # Direct effects on outcome\n",
    "        ('Amyloid', 'Cognitive_Status'), ('TAU', 'Cognitive_Status'), ('Hippocampus', 'Cognitive_Status')\n",
    "    ]\n",
    "    G.add_edges_from(edges)\n",
    "    \n",
    "    # Draw the DAG (McElreath style)\n",
    "    ax.set_xlim(-0.5, 4.5)\n",
    "    ax.set_ylim(-1, 4.5)\n",
    "    \n",
    "    # Color coding for variable types\n",
    "    colors = {\n",
    "        'Age': '#E74C3C', 'Education': '#27AE60', 'APOE4': '#8E44AD',  # Exogenous (fundamental)\n",
    "        'Amyloid': '#F39C12', 'TAU': '#E67E22', 'Hippocampus': '#3498DB',  # Mediators\n",
    "        'Cognitive_Status': '#34495E'  # Outcome\n",
    "    }\n",
    "    \n",
    "    # Draw nodes\n",
    "    for node, (x, y) in pos.items():\n",
    "        circle = plt.Circle((x, y), 0.3, color=colors[node], alpha=0.7, zorder=3)\n",
    "        ax.add_patch(circle)\n",
    "        ax.text(x, y, node.replace('_', '\\n'), ha='center', va='center', \n",
    "                fontsize=9, fontweight='bold', color='white', zorder=4)\n",
    "    \n",
    "    # Draw edges with arrows\n",
    "    for edge in edges:\n",
    "        start = pos[edge[0]]\n",
    "        end = pos[edge[1]]\n",
    "        \n",
    "        # Calculate arrow position (stop at circle edge)\n",
    "        dx, dy = end[0] - start[0], end[1] - start[1]\n",
    "        length = np.sqrt(dx**2 + dy**2)\n",
    "        dx_norm, dy_norm = dx/length, dy/length\n",
    "        \n",
    "        start_adj = (start[0] + 0.3 * dx_norm, start[1] + 0.3 * dy_norm)\n",
    "        end_adj = (end[0] - 0.3 * dx_norm, end[1] - 0.3 * dy_norm)\n",
    "        \n",
    "        ax.annotate('', xy=end_adj, xytext=start_adj,\n",
    "                    arrowprops=dict(arrowstyle='->', lw=1.5, color='#2C3E50', alpha=0.8))\n",
    "    \n",
    "    # Legend\n",
    "    legend_elements = [\n",
    "        mpatches.Patch(color='#E74C3C', label='Age (Exogenous)'),\n",
    "        mpatches.Patch(color='#27AE60', label='Education (Protective)'),\n",
    "        mpatches.Patch(color='#8E44AD', label='APOE4 (Genetic Risk)'),\n",
    "        mpatches.Patch(color='#F39C12', label='Biomarkers (Mediators)'),\n",
    "        mpatches.Patch(color='#34495E', label='Cognitive Status (Outcome)')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(1.3, 1))\n",
    "    \n",
    "    ax.set_title('Alzheimer\\'s Disease Causal DAG\\n(Following McElreath\\'s Methodology)', \n",
    "                 fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return G, pos\n",
    "\n",
    "# Create and display the DAG\n",
    "print(\" STEP 2: CAUSAL DIAGRAM CONSTRUCTION\")\n",
    "print(\"=\" * 50)\n",
    "print(\"McElreath: 'Draw your assumptions before you draw conclusions'\")\n",
    "print(\"\\nCreating Directed Acyclic Graph (DAG) for Alzheimer's disease...\")\n",
    "\n",
    "dag_graph, node_positions = create_alzheimers_dag()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Confound Analysis \n",
    "\n",
    "**McElreath's Key Insight:** *\"Confounders are variables that influence both the treatment and outcome. Control for confounders, avoid controlling for mediators and colliders.\"*\n",
    "\n",
    "### Identifying Confounders in our DAG:\n",
    "\n",
    "**For Age â†’ Cognitive Status:**\n",
    "- **No confounders** (Age is exogenous)\n",
    "- **Mediators**: Amyloid, TAU, Hippocampus (DO NOT control)\n",
    "\n",
    "**For Education â†’ Cognitive Status:**\n",
    "- **No confounders** (Education is exogenous)  \n",
    "- **Mediators**: Hippocampus (DO NOT control - it's protective pathway)\n",
    "\n",
    "**For APOE4 â†’ Cognitive Status:**\n",
    "- **No confounders** (APOE4 is genetic/exogenous)\n",
    "- **Mediators**: Amyloid, TAU (DO NOT control - they ARE the causal pathway)\n",
    "\n",
    "**For Biomarkers â†’ Cognitive Status:**\n",
    "- **Confounders**: Age, APOE4 (control for these)\n",
    "- **Education**: Not a confounder but might moderate effects\n",
    "\n",
    "### McElreath's Model Strategy:\n",
    "\n",
    "1. **Total Effects Model**: Include only exogenous variables (Age, Education, APOE4)\n",
    "2. **Direct Effects Model**: Include biomarkers + their confounders (Age, APOE4)  \n",
    "3. **Avoid**: Controlling for mediators when estimating total effects\n",
    "4. **Compare**: How effects change when including different variable sets\n",
    "\n",
    "### Models to Build:\n",
    "- **M1**: Cognitive ~ Age + Education + APOE4 (total effects)\n",
    "- **M2**: Cognitive ~ Age + Education + APOE4 + Biomarkers (direct effects)\n",
    "- **M3**: Stratified models by APOE4 status (effect modification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Generate Data Following Our Causal Story\n",
    "# McElreath: \"Simulate data from your assumed process\"\n",
    "\n",
    "def generate_adni_data_mcelreath_style(n=2500, seed=42):\n",
    "    \"\"\"Generate ADNI data following our causal DAG\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    print(\"Generating data following our causal story...\")\n",
    "    print(\" Using the DAG to simulate realistic causal relationships\")\n",
    "    \n",
    "    # 1. Exogenous variables (no parents in DAG)\n",
    "    age = np.random.normal(72, 8, n)  # Age in years\n",
    "    age = np.clip(age, 60, 90)\n",
    "    age_scaled = (age - age.mean()) / age.std()\n",
    "    \n",
    "    education = np.random.normal(14, 3, n)  # Years of education\n",
    "    education = np.clip(education, 8, 20)\n",
    "    education_scaled = (education - education.mean()) / education.std()\n",
    "    \n",
    "    apoe4 = np.random.binomial(1, 0.25, n)  # 25% carry APOE4\n",
    "    \n",
    "    # 2. First-level mediators (Age and APOE4 â†’ Biomarkers)\n",
    "    # Amyloid accumulation: Age + APOE4 increase it\n",
    "    amyloid_linear = (\n",
    "        0.4 * age_scaled +           # Age increases amyloid\n",
    "        0.6 * apoe4 +               # APOE4 dramatically increases amyloid\n",
    "        np.random.normal(0, 0.3, n) # Individual variation\n",
    "    )\n",
    "    amyloid = 1 / (1 + np.exp(-amyloid_linear))  # Sigmoid transform to [0,1]\n",
    "    \n",
    "    # TAU pathology: Age + APOE4 + Amyloid â†’ TAU\n",
    "    tau_linear = (\n",
    "        0.3 * age_scaled +           # Age increases tau\n",
    "        0.5 * apoe4 +               # APOE4 increases tau\n",
    "        0.7 * amyloid +             # Amyloid promotes tau (key pathway!)\n",
    "        np.random.normal(0, 0.3, n) # Individual variation\n",
    "    )\n",
    "    tau = 1 / (1 + np.exp(-tau_linear))  # Sigmoid to [0,1]\n",
    "    \n",
    "    # 3. Second-level mediators (everything â†’ Hippocampal volume)\n",
    "    hippocampus_linear = (\n",
    "        -0.3 * age_scaled +          # Age reduces volume\n",
    "        0.4 * education_scaled +     # Education protects (cognitive reserve!)\n",
    "        -0.6 * tau +                # TAU destroys hippocampus\n",
    "        -0.4 * amyloid +            # Amyloid damages hippocampus\n",
    "        np.random.normal(0, 0.3, n) # Individual variation\n",
    "    )\n",
    "    hippocampus = 1 / (1 + np.exp(-hippocampus_linear))  # Sigmoid to [0,1]\n",
    "    \n",
    "    # 4. Final outcome: Cognitive Status (ordinal 0-4)\n",
    "    # All paths converge here\n",
    "    cognitive_linear = (\n",
    "        0.5 * age_scaled +           # Direct age effect (beyond biomarkers)\n",
    "        -0.8 * education_scaled +    # Education protective (beyond hippocampus)\n",
    "        0.3 * apoe4 +               # Direct genetic effect\n",
    "        0.9 * amyloid +             # Direct amyloid toxicity\n",
    "        1.1 * tau +                 # TAU is most toxic\n",
    "        -1.0 * hippocampus +        # Hippocampal preservation protects\n",
    "        np.random.normal(0, 0.4, n) # Individual variation\n",
    "    )\n",
    "    \n",
    "    # Convert to ordinal categories using cutpoints\n",
    "    cutpoints = [-1.2, -0.3, 0.5, 1.5]  # Carefully chosen thresholds\n",
    "    cognitive_status = np.zeros(n, dtype=int)\n",
    "    for i, cut in enumerate(cutpoints):\n",
    "        cognitive_status[cognitive_linear > cut] = i + 1\n",
    "    \n",
    "    # Create dataset\n",
    "    data = pd.DataFrame({\n",
    "        'subject_id': range(1, n + 1),\n",
    "        'age': age,\n",
    "        'age_scaled': age_scaled,\n",
    "        'education': education,\n",
    "        'education_scaled': education_scaled,\n",
    "        'apoe4': apoe4,\n",
    "        'amyloid': amyloid,\n",
    "        'tau': tau,\n",
    "        'hippocampus': hippocampus,\n",
    "        'cognitive_status': cognitive_status\n",
    "    })\n",
    "    \n",
    "    # Add labels for interpretation\n",
    "    status_labels = {\n",
    "        0: 'Normal', 1: 'Subjective Decline', 2: 'MCI', \n",
    "        3: 'Mild Dementia', 4: 'Moderate Dementia'\n",
    "    }\n",
    "    data['cognitive_label'] = data['cognitive_status'].map(status_labels)\n",
    "    \n",
    "    # Display data story validation\n",
    "    print(f\"\\n Generated {n} subjects following causal DAG\")\n",
    "    print(f\" Cognitive status distribution:\")\n",
    "    print(data['cognitive_label'].value_counts().sort_index())\n",
    "    \n",
    "    print(f\"\\nðŸ§¬ Key relationships (should match our causal story):\")\n",
    "    print(f\"Age â†’ Amyloid correlation: {data['age_scaled'].corr(data['amyloid']):.3f}\")\n",
    "    print(f\"APOE4 â†’ Amyloid difference: {data.groupby('apoe4')['amyloid'].mean().diff().iloc[1]:.3f}\")\n",
    "    print(f\"Amyloid â†’ TAU correlation: {data['amyloid'].corr(data['tau']):.3f}\")\n",
    "    print(f\"Education â†’ Hippocampus correlation: {data['education_scaled'].corr(data['hippocampus']):.3f}\")\n",
    "    print(f\"TAU â†’ Cognitive Status correlation: {data['tau'].corr(data['cognitive_status']):.3f}\")\n",
    "    \n",
    "    return data, status_labels\n",
    "\n",
    "# Generate the data\n",
    "print(\" STEP 4: DATA GENERATION FOLLOWING CAUSAL STORY\")\n",
    "print(\"=\" * 60)\n",
    "data, status_labels = generate_adni_data_mcelreath_style(n=2500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Statistical Models Following Causal Strategy \n",
    "\n",
    "**McElreath's Modeling Strategy:** *\"Don't directly interpret parameters - generate predictions!\"*\n",
    "\n",
    "Based on our DAG analysis, we'll build multiple models to answer different causal questions:\n",
    "\n",
    "### Model M1: Total Effects (Exogenous Variables Only)\n",
    "- **Purpose**: Estimate total causal effects of fundamental variables\n",
    "- **Variables**: Age + Education + APOE4 â†’ Cognitive Status\n",
    "- **Interpretation**: Total effect including all pathways\n",
    "\n",
    "### Model M2: Direct Effects (Include Mediators) \n",
    "- **Purpose**: Estimate direct effects after controlling for mediators\n",
    "- **Variables**: Age + Education + APOE4 + Biomarkers â†’ Cognitive Status  \n",
    "- **Interpretation**: Direct effects, with biological pathways controlled\n",
    "\n",
    "### Model M3: Stratified by APOE4 (Effect Modification)\n",
    "- **Purpose**: Test if effects differ by genetic risk\n",
    "- **Strategy**: Separate models for APOE4 carriers vs non-carriers\n",
    "- **Interpretation**: Gene-environment interactions\n",
    "\n",
    "**Key Insight**: Compare M1 vs M2 to see how much effect operates through biomarkers vs direct pathways.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Build Statistical Models Following McElreath's Causal Strategy\n",
    "\n",
    "print(\" STEP 5: STATISTICAL MODELING\")\n",
    "print(\"=\" * 50)\n",
    "print(\"McElreath: 'Statistical models should embody your causal assumptions'\")\n",
    "\n",
    "# Validate ordinal data first\n",
    "y = data['cognitive_status'].values\n",
    "K = len(np.unique(y))\n",
    "\n",
    "print(f\"\\n Response Variable Summary:\")\n",
    "print(f\"Categories: {K} (0 = Normal â†’ 4 = Moderate Dementia)\")\n",
    "print(f\"Distribution: {np.bincount(y)}\")\n",
    "\n",
    "# Validate with our package\n",
    "validation_result = bo.validate_ordinal_data(y, np.column_stack([data['age_scaled'], data['education_scaled']]))\n",
    "print(f\" Data validation: {validation_result}\")\n",
    "\n",
    "# Model M1: Total Effects (Exogenous Variables Only)\n",
    "print(f\"\\n MODEL M1: TOTAL EFFECTS\")\n",
    "print(\"Variables: Age + Education + APOE4\")\n",
    "print(\"Purpose: Estimate total causal effects including all pathways\")\n",
    "\n",
    "# Prepare design matrix for M1\n",
    "X_total = np.column_stack([\n",
    "    data['age_scaled'].values,\n",
    "    data['education_scaled'].values, \n",
    "    data['apoe4'].values\n",
    "])\n",
    "\n",
    "feature_names_total = ['age_scaled', 'education_scaled', 'apoe4']\n",
    "\n",
    "print(f\"Design matrix M1: {X_total.shape}\")\n",
    "\n",
    "# Prior specification (McElreath: \"Priors should be scientifically reasonable\")\n",
    "priors_m1 = {\n",
    "    'beta_sd': 1.0,      # Moderate effects expected for fundamental variables\n",
    "    'cutpoint_sd': 2.0,  # Allow flexible thresholds\n",
    "    'intercept_sd': 2.0  # Flexible baseline\n",
    "}\n",
    "\n",
    "# Build Model M1\n",
    "m1_total = bo.cumulative_model(\n",
    "    y=y, X=X_total, K=K,\n",
    "    link='logit',\n",
    "    priors=priors_m1,\n",
    "    model_name='alzheimers_total'\n",
    ")\n",
    "\n",
    "print(\" Model M1 (Total Effects) built\")\n",
    "\n",
    "# Model M2: Direct Effects (Include Biomarkers)\n",
    "print(f\"\\nðŸ§¬ MODEL M2: DIRECT EFFECTS\")\n",
    "print(\"Variables: Age + Education + APOE4 + Amyloid + TAU + Hippocampus\")\n",
    "print(\"Purpose: Estimate direct effects after controlling for biological mediators\")\n",
    "\n",
    "# Prepare design matrix for M2 \n",
    "X_direct = np.column_stack([\n",
    "    data['age_scaled'].values,\n",
    "    data['education_scaled'].values,\n",
    "    data['apoe4'].values,\n",
    "    data['amyloid'].values,\n",
    "    data['tau'].values,\n",
    "    data['hippocampus'].values\n",
    "])\n",
    "\n",
    "feature_names_direct = ['age_scaled', 'education_scaled', 'apoe4', 'amyloid', 'tau', 'hippocampus']\n",
    "\n",
    "print(f\"Design matrix M2: {X_direct.shape}\")\n",
    "\n",
    "# Priors for M2 (slightly tighter for biomarkers)\n",
    "priors_m2 = {\n",
    "    'beta_sd': 1.2,      # Allow stronger effects for biomarkers\n",
    "    'cutpoint_sd': 2.0,  # Same flexible thresholds\n",
    "    'intercept_sd': 2.0  # Same baseline\n",
    "}\n",
    "\n",
    "# Build Model M2\n",
    "m2_direct = bo.cumulative_model(\n",
    "    y=y, X=X_direct, K=K,\n",
    "    link='logit', \n",
    "    priors=priors_m2,\n",
    "    model_name='alzheimers_direct'\n",
    ")\n",
    "\n",
    "print(\" Model M2 (Direct Effects) built\")\n",
    "\n",
    "# Store models for comparison\n",
    "models = {\n",
    "    'M1_Total': m1_total,\n",
    "    'M2_Direct': m2_direct\n",
    "}\n",
    "\n",
    "print(f\"\\n Model Summary:\")\n",
    "print(f\"M1 Total Effects: {len(feature_names_total)} predictors\")\n",
    "print(f\"M2 Direct Effects: {len(feature_names_direct)} predictors\") \n",
    "print(f\"Response: {K} ordinal categories\")\n",
    "print(\" Statistical models built following causal strategy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Prior Predictive Simulation \n",
    "\n",
    "**McElreath's Key Insight:** *\"Prior predictive simulation reveals what your model assumes before seeing data.\"*\n",
    "\n",
    "We'll simulate predictions from our priors to check if they generate reasonable ranges for cognitive status. This helps us catch unrealistic assumptions before fitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Prior Predictive Simulation (McElreath Style)\n",
    "\n",
    "print(\" STEP 6: PRIOR PREDICTIVE SIMULATION\")\n",
    "print(\"=\" * 50)\n",
    "print(\"McElreath: 'Simulate from your priors to check assumptions'\")\n",
    "\n",
    "# Prior predictive for Model M1 (Total Effects)\n",
    "print(\"\\n Prior Predictive for M1 (Total Effects)\")\n",
    "print(\"Checking if priors generate reasonable cognitive status predictions...\")\n",
    "\n",
    "prior_pred_m1 = bo.run_prior_predictive(\n",
    "    m1_total,\n",
    "    draws=500,\n",
    "    y_obs=y,\n",
    "    model_name=\"M1 Total Effects\",\n",
    "    custom_plots={\n",
    "        'prior_samples': False,\n",
    "        'mean_distribution': True,\n",
    "        'observed': True,\n",
    "        'category_proportions': True\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\" M1 prior predictive completed\")\n",
    "\n",
    "# Prior predictive for Model M2 (Direct Effects)\n",
    "print(\"\\nðŸ§¬ Prior Predictive for M2 (Direct Effects)\")\n",
    "print(\"Checking if biomarker model priors are reasonable...\")\n",
    "\n",
    "prior_pred_m2 = bo.run_prior_predictive(\n",
    "    m2_direct,\n",
    "    draws=500,\n",
    "    y_obs=y,\n",
    "    model_name=\"M2 Direct Effects\",\n",
    "    custom_plots={\n",
    "        'prior_samples': False,\n",
    "        'mean_distribution': True,\n",
    "        'observed': True,\n",
    "        'category_proportions': True\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\" M2 prior predictive completed\")\n",
    "\n",
    "# McElreath-style prior interpretation\n",
    "print(\"\\n Prior Predictive Assessment:\")\n",
    "print(\" Check 1: Do priors cover all cognitive status categories?\")\n",
    "print(\" Check 2: Are predictions concentrated around reasonable values?\")\n",
    "print(\" Check 3: Do predictions have appropriate uncertainty?\")\n",
    "print(\" Check 4: Are extreme predictions (all normal/all dementia) rare?\")\n",
    "\n",
    "print(\"\\n McElreath's Prior Philosophy:\")\n",
    "print(\"â€¢ Priors should be weakly informative\")\n",
    "print(\"â€¢ They should rule out unreasonable predictions\")\n",
    "print(\"â€¢ They should NOT be too confident before seeing data\")\n",
    "print(\"â€¢ Prior predictive distributions should be plausible\")\n",
    "\n",
    "print(\"\\n Prior predictive simulation completed\")\n",
    "print(\"Ready to proceed with model fitting\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Model Fitting \n",
    "\n",
    "**McElreath's Principle:** *\"The machine should fit the model, not the model fit the machine.\"*\n",
    "\n",
    "We'll use robust MCMC sampling to ensure reliable posterior estimates. McElreath emphasizes checking diagnostics carefully before interpreting any results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Model Fitting Following McElreath's Robust Approach\n",
    "\n",
    "print(\" STEP 7: MODEL FITTING\")\n",
    "print(\"=\" * 50)\n",
    "print(\"McElreath: 'The machine should fit the model, not the model fit the machine'\")\n",
    "\n",
    "# Configure robust sampling (McElreath emphasizes reliability over speed)\n",
    "sampling_config = {\n",
    "    'draws': 2000,           # Plenty of samples for reliable estimates\n",
    "    'tune': 1500,            # Adequate warmup for complex models\n",
    "    'chains': 4,             # Multiple chains to check convergence\n",
    "    'target_accept': 0.9,    # High acceptance rate for stability\n",
    "    'max_treedepth': 12,     # Allow deep trees for complex geometry\n",
    "    'return_inferencedata': True,\n",
    "    'enable_log_likelihood': True,      # For model comparison\n",
    "    'enable_posterior_predictive': True # For validation\n",
    "}\n",
    "\n",
    "print(f\"\\n Sampling Configuration (McElreath-style robust):\")\n",
    "print(f\"â€¢ Draws: {sampling_config['draws']} per chain\")\n",
    "print(f\"â€¢ Chains: {sampling_config['chains']}\")\n",
    "print(f\"â€¢ Target accept: {sampling_config['target_accept']}\")\n",
    "print(\"â€¢ Philosophy: Reliable estimates over speed\")\n",
    "\n",
    "# Fit Model M1 (Total Effects)\n",
    "print(f\"\\n Fitting M1: Total Effects Model\")\n",
    "print(\"Variables: Age + Education + APOE4\")\n",
    "\n",
    "idata_m1 = bo.fit_ordinal_model(m1_total, **sampling_config)\n",
    "\n",
    "print(\" M1 Total Effects model fitted\")\n",
    "\n",
    "# Fit Model M2 (Direct Effects)  \n",
    "print(f\"\\nðŸ§¬ Fitting M2: Direct Effects Model\")\n",
    "print(\"Variables: Age + Education + APOE4 + Biomarkers\")\n",
    "\n",
    "idata_m2 = bo.fit_ordinal_model(m2_direct, **sampling_config)\n",
    "\n",
    "print(\" M2 Direct Effects model fitted\")\n",
    "\n",
    "# Store inference data\n",
    "idatas = {\n",
    "    'M1_Total': idata_m1,\n",
    "    'M2_Direct': idata_m2\n",
    "}\n",
    "\n",
    "print(f\"\\n Fitting Summary:\")\n",
    "print(f\"â€¢ Total samples per model: {sampling_config['chains'] * sampling_config['draws']}\")\n",
    "print(f\"â€¢ Models fitted: {len(idatas)}\")\n",
    "print(\"â€¢ Ready for diagnostic checks\")\n",
    "\n",
    "# Quick convergence check (McElreath: \"Always check convergence first!\")\n",
    "print(f\"\\n Quick Convergence Check:\")\n",
    "for name, idata in idatas.items():\n",
    "    try:\n",
    "        # Get R-hat summary\n",
    "        summary = az.summary(idata, round_to=3)\n",
    "        max_rhat = summary['r_hat'].max()\n",
    "        min_ess = summary['ess_bulk'].min()\n",
    "        \n",
    "        print(f\"{name:12s}: RÌ‚_max = {max_rhat:.3f}, ESS_min = {min_ess:.0f}\")\n",
    "        \n",
    "        # McElreath's convergence criteria\n",
    "        if max_rhat < 1.01 and min_ess > 400:\n",
    "            print(f\"                Converged (McElreath criteria)\")\n",
    "        else:\n",
    "            print(f\"                 Check convergence (RÌ‚ > 1.01 or ESS < 400)\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"{name:12s}:   Error checking convergence: {e}\")\n",
    "\n",
    "print(\"\\n Model fitting completed - ready for validation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Posterior Validation \n",
    "\n",
    "**McElreath's Validation Strategy:** *\"Never trust a model you haven't thoroughly checked.\"*\n",
    "\n",
    "1. **Computational Diagnostics** - Check MCMC machinery\n",
    "2. **Posterior Predictive Checks** - Does the model capture the data?\n",
    "3. **Model Comparison** - Which model answers our question best?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Posterior Validation Following McElreath\n",
    "\n",
    "print(\" STEP 8: POSTERIOR VALIDATION\")\n",
    "print(\"=\" * 50)\n",
    "print(\"McElreath: 'Never trust a model you haven't thoroughly checked'\")\n",
    "\n",
    "# 1. Computational Diagnostics\n",
    "print(\"\\n COMPUTATIONAL DIAGNOSTICS\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "from bayes_ordinal.workflow.computation import (\n",
    "    diagnose_computational_issues,\n",
    "    fake_data_simulation\n",
    ")\n",
    "\n",
    "# Check computational integrity\n",
    "print(\"Diagnosing computational issues...\")\n",
    "for name, idata in idatas.items():\n",
    "    print(f\"\\n{name} Computational Check:\")\n",
    "    comp_issues = diagnose_computational_issues(idata)\n",
    "\n",
    "# Fake data simulation (McElreath: \"Check your model with simulated data\")\n",
    "print(\"\\nModel implementation validation:\")\n",
    "fake_m1 = fake_data_simulation(m1_total, n_simulations=5)\n",
    "fake_m2 = fake_data_simulation(m2_direct, n_simulations=5)\n",
    "\n",
    "print(f\"M1 fake data success: {fake_m1['n_successful']}/{fake_m1['n_simulations']}\")\n",
    "print(f\"M2 fake data success: {fake_m2['n_successful']}/{fake_m2['n_simulations']}\")\n",
    "\n",
    "# 2. Comprehensive Diagnostics\n",
    "print(f\"\\n COMPREHENSIVE DIAGNOSTICS\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "from bayes_ordinal.workflow.diagnostics import run_comprehensive_diagnostics\n",
    "\n",
    "# Run detailed diagnostics\n",
    "print(\"Running comprehensive diagnostics for both models...\")\n",
    "\n",
    "m1_diag = run_comprehensive_diagnostics(idata_m1, model_name=\"M1 Total Effects\")\n",
    "m2_diag = run_comprehensive_diagnostics(idata_m2, model_name=\"M2 Direct Effects\")\n",
    "\n",
    "print(f\"\\nDiagnostic Summary:\")\n",
    "print(f\"M1 Total converged: {m1_diag['converged']}\")\n",
    "print(f\"M2 Direct converged: {m2_diag['converged']}\")\n",
    "\n",
    "# 3. Posterior Predictive Checks\n",
    "print(f\"\\n POSTERIOR PREDICTIVE CHECKS\")\n",
    "print(\"-\" * 40)\n",
    "print(\"McElreath: 'Does your model reproduce the features of the data?'\")\n",
    "\n",
    "# Check if models reproduce observed data patterns\n",
    "print(\"\\nM1 Total Effects - Posterior Predictive:\")\n",
    "bo.run_posterior_predictive(m1_total, idata_m1, kind='proportions', figsize=(10, 6))\n",
    "\n",
    "print(\"\\nM2 Direct Effects - Posterior Predictive:\")\n",
    "bo.run_posterior_predictive(m2_direct, idata_m2, kind='proportions', figsize=(10, 6))\n",
    "\n",
    "# 4. Model Comparison (McElreath style)\n",
    "print(f\"\\n MODEL COMPARISON\")\n",
    "print(\"-\" * 25)\n",
    "print(\"McElreath: 'Compare models to understand what the data are telling you'\")\n",
    "\n",
    "from bayes_ordinal.workflow.cross_validation import (\n",
    "    compare_models_stacking, \n",
    "    display_comparison_results\n",
    ")\n",
    "\n",
    "# Compare total vs direct effects models\n",
    "comparison_results = compare_models_stacking(\n",
    "    models=models,\n",
    "    idatas=idatas,\n",
    "    ic=\"loo\",\n",
    "    include_stacking=True\n",
    ")\n",
    "\n",
    "print(\"\\n Model Comparison Results:\")\n",
    "display_comparison_results(comparison_results)\n",
    "\n",
    "# McElreath interpretation\n",
    "best_model = comparison_results.get('best_model', 'M1_Total')\n",
    "print(f\"\\n McElreath-style Interpretation:\")\n",
    "print(f\"Best model: {best_model}\")\n",
    "\n",
    "if best_model == 'M1_Total':\n",
    "    print(\"â€¢ Total effects model preferred\")\n",
    "    print(\"â€¢ Including biomarkers doesn't improve prediction\")\n",
    "    print(\"â€¢ Age, Education, APOE4 capture most causal effects\")\n",
    "else:\n",
    "    print(\"â€¢ Direct effects model preferred\") \n",
    "    print(\"â€¢ Biomarkers provide additional predictive information\")\n",
    "    print(\"â€¢ Both direct and mediated pathways matter\")\n",
    "\n",
    "print(\"\\n Posterior validation completed\")\n",
    "print(\" Models are reliable and ready for causal interpretation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Counterfactual Reasoning \n",
    "\n",
    "**McElreath's Core Philosophy:** *\"Statistical models are causal models. Use them to simulate interventions.\"*\n",
    "\n",
    "Now we answer the key causal questions:\n",
    "1. **What if we could reduce amyloid/TAU?** (Drug intervention)\n",
    "2. **What if everyone had high education?** (Policy intervention)  \n",
    "3. **How do total vs direct effects compare?** (Mechanism understanding)\n",
    "\n",
    "This is where McElreath's approach shines - moving from correlation to causation through simulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Counterfactual Reasoning (McElreath's Causal Inference)\n",
    "\n",
    "print(\" STEP 9: COUNTERFACTUAL REASONING\")\n",
    "print(\"=\" * 50)\n",
    "print(\"McElreath: 'Statistical models are causal models - use them to simulate interventions'\")\n",
    "\n",
    "from bayes_ordinal.analysis.counterfactual import run_counterfactual_analysis, plot_counterfactual_results\n",
    "\n",
    "# Select model for counterfactual analysis\n",
    "best_model_name = comparison_results.get('best_model', 'M1_Total')\n",
    "best_model_obj = models[best_model_name]\n",
    "best_idata = idatas[best_model_name]\n",
    "\n",
    "print(f\"\\nUsing {best_model_name} for counterfactual analysis\")\n",
    "\n",
    "# Define intervention scenarios (McElreath: \"Think like you're doing experiments\")\n",
    "print(f\"\\nðŸ§ª INTERVENTION SCENARIOS\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "if best_model_name == 'M1_Total':\n",
    "    # Total effects model - fundamental interventions only\n",
    "    feature_names = feature_names_total\n",
    "    scenarios = {\n",
    "        \"Current Population\": {\n",
    "            \"age_scaled\": 0.0,      # Average age\n",
    "            \"education_scaled\": 0.0, # Average education  \n",
    "            \"apoe4\": 0.25           # Population prevalence\n",
    "        },\n",
    "        \"Young Population\": {\n",
    "            \"age_scaled\": -1.5,     # Much younger\n",
    "            \"education_scaled\": 0.0,\n",
    "            \"apoe4\": 0.25\n",
    "        },\n",
    "        \"High Education Policy\": {\n",
    "            \"age_scaled\": 0.0,\n",
    "            \"education_scaled\": 1.5, # Much higher education\n",
    "            \"apoe4\": 0.25\n",
    "        },\n",
    "        \"APOE4 Carriers\": {\n",
    "            \"age_scaled\": 0.0,\n",
    "            \"education_scaled\": 0.0,\n",
    "            \"apoe4\": 1.0            # All carriers\n",
    "        },\n",
    "        \"Optimal Prevention\": {\n",
    "            \"age_scaled\": -1.0,     # Younger\n",
    "            \"education_scaled\": 1.5, # High education\n",
    "            \"apoe4\": 0.0            # No genetic risk\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"Total Effects Scenarios:\")\n",
    "    print(\"â€¢ Current Population - baseline\")\n",
    "    print(\"â€¢ Young Population - age intervention\")\n",
    "    print(\"â€¢ High Education Policy - education intervention\")\n",
    "    print(\"â€¢ APOE4 Carriers - genetic risk group\")\n",
    "    print(\"â€¢ Optimal Prevention - combined interventions\")\n",
    "    \n",
    "else:\n",
    "    # Direct effects model - biomarker interventions possible\n",
    "    feature_names = feature_names_direct\n",
    "    scenarios = {\n",
    "        \"Current Population\": {\n",
    "            \"age_scaled\": 0.0, \"education_scaled\": 0.0, \"apoe4\": 0.25,\n",
    "            \"amyloid\": 0.5, \"tau\": 0.5, \"hippocampus\": 0.5\n",
    "        },\n",
    "        \"Amyloid Drug\": {\n",
    "            \"age_scaled\": 0.0, \"education_scaled\": 0.0, \"apoe4\": 0.25,\n",
    "            \"amyloid\": 0.1, \"tau\": 0.5, \"hippocampus\": 0.5  # Reduce amyloid\n",
    "        },\n",
    "        \"TAU Drug\": {\n",
    "            \"age_scaled\": 0.0, \"education_scaled\": 0.0, \"apoe4\": 0.25,\n",
    "            \"amyloid\": 0.5, \"tau\": 0.1, \"hippocampus\": 0.5  # Reduce TAU\n",
    "        },\n",
    "        \"Combined Therapy\": {\n",
    "            \"age_scaled\": 0.0, \"education_scaled\": 0.0, \"apoe4\": 0.25,\n",
    "            \"amyloid\": 0.1, \"tau\": 0.1, \"hippocampus\": 0.7  # Reduce pathology\n",
    "        },\n",
    "        \"Education + Therapy\": {\n",
    "            \"age_scaled\": 0.0, \"education_scaled\": 1.5, \"apoe4\": 0.25,\n",
    "            \"amyloid\": 0.1, \"tau\": 0.1, \"hippocampus\": 0.8  # Combined approach\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"Direct Effects Scenarios:\")\n",
    "    print(\"â€¢ Current Population - baseline\")\n",
    "    print(\"â€¢ Amyloid Drug - reduce amyloid pathology\")\n",
    "    print(\"â€¢ TAU Drug - reduce TAU pathology\")  \n",
    "    print(\"â€¢ Combined Therapy - reduce both pathologies\")\n",
    "    print(\"â€¢ Education + Therapy - comprehensive intervention\")\n",
    "\n",
    "# Run counterfactual analysis\n",
    "print(f\"\\n Running Counterfactual Simulations...\")\n",
    "print(\"McElreath: 'Generate predictions, don't just interpret coefficients'\")\n",
    "\n",
    "counterfactual_results = run_counterfactual_analysis(\n",
    "    best_model_obj,\n",
    "    best_idata,\n",
    "    scenarios,\n",
    "    feature_names=feature_names\n",
    ")\n",
    "\n",
    "print(\" Counterfactual simulations completed\")\n",
    "\n",
    "# Visualize results (McElreath loves clear visualizations)\n",
    "print(f\"\\n Creating Intervention Comparison Plots...\")\n",
    "plot_counterfactual_results(counterfactual_results, figsize=(16, 10))\n",
    "\n",
    "print(\" Counterfactual visualization completed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Causal Interpretation & Conclusions \n",
    "\n",
    "**McElreath's Final Step:** *\"What do these results mean for understanding and intervention?\"*\n",
    "\n",
    "Time to synthesize our causal analysis and provide actionable insights following McElreath's interpretative framework.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: McElreath-Style Causal Interpretation\n",
    "\n",
    "print(\" STEP 10: CAUSAL INTERPRETATION & CONCLUSIONS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"McElreath: 'What do these results mean for understanding and intervention?'\")\n",
    "\n",
    "# Extract parameter estimates for interpretation\n",
    "model_prefix = f\"alzheimers_{best_model_name.lower().split('_')[1]}\"\n",
    "param_summary = az.summary(best_idata, var_names=[f\"{model_prefix}::beta\"], round_to=3)\n",
    "\n",
    "print(f\"\\n CAUSAL PARAMETER ESTIMATES\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Model: {best_model_name}\")\n",
    "\n",
    "# Get coefficients\n",
    "beta_means = param_summary.loc[param_summary.index.str.contains('beta'), 'mean'].values\n",
    "beta_hdi_low = param_summary.loc[param_summary.index.str.contains('beta'), 'hdi_3%'].values\n",
    "beta_hdi_high = param_summary.loc[param_summary.index.str.contains('beta'), 'hdi_97%'].values\n",
    "\n",
    "# Interpret each coefficient causally\n",
    "if best_model_name == 'M1_Total':\n",
    "    labels = ['Age (per SD)', 'Education (per SD)', 'APOE4 (carrier vs non)']\n",
    "else:\n",
    "    labels = ['Age (per SD)', 'Education (per SD)', 'APOE4 (carrier vs non)',\n",
    "              'Amyloid (0-1)', 'TAU (0-1)', 'Hippocampus (0-1)']\n",
    "\n",
    "print(f\"\\nCAUSAL EFFECTS (on log-odds scale):\")\n",
    "for i, (label, coef, low, high) in enumerate(zip(labels, beta_means, beta_hdi_low, beta_hdi_high)):\n",
    "    direction = \"INCREASES\" if coef > 0 else \"DECREASES\"\n",
    "    strength = \"STRONG\" if abs(coef) > 0.6 else \"MODERATE\" if abs(coef) > 0.3 else \"WEAK\"\n",
    "    \n",
    "    print(f\"\\n{label}:\")\n",
    "    print(f\"  {strength} causal effect that {direction} cognitive decline risk\")\n",
    "    print(f\"  Coefficient: {coef:+.3f} (95% HDI: [{low:.3f}, {high:.3f}])\")\n",
    "\n",
    "# Counterfactual interpretation (McElreath style)\n",
    "print(f\"\\nðŸ§ª INTERVENTION EFFECTS\")\n",
    "print(\"=\" * 30)\n",
    "print(\"McElreath: 'Focus on the size of effects, not just their existence'\")\n",
    "\n",
    "if \"summary\" in counterfactual_results:\n",
    "    baseline_scenario = \"Current Population\"\n",
    "    if baseline_scenario in counterfactual_results[\"summary\"]:\n",
    "        baseline_mean = counterfactual_results[\"summary\"][baseline_scenario][\"mean\"]\n",
    "        \n",
    "        print(f\"\\nBaseline ({baseline_scenario}): {baseline_mean:.2f}\")\n",
    "        print(\"Intervention Effects:\")\n",
    "        \n",
    "        for scenario, result in counterfactual_results[\"summary\"].items():\n",
    "            if scenario != baseline_scenario:\n",
    "                effect_mean = result[\"mean\"]\n",
    "                effect_size = effect_mean - baseline_mean\n",
    "                most_likely = result[\"mode\"]\n",
    "                \n",
    "                print(f\"  {scenario:20s}: {effect_size:+.2f} â†’ {status_labels[most_likely]}\")\n",
    "\n",
    "# McElreath's practical conclusions\n",
    "print(f\"\\n MCELREATH-STYLE CONCLUSIONS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(f\"\\n1. CAUSAL UNDERSTANDING:\")\n",
    "if best_model_name == 'M1_Total':\n",
    "    print(\"   â€¢ Age, Education, and APOE4 are the fundamental causal drivers\")\n",
    "    print(\"   â€¢ Biomarkers likely mediate these effects (not independent causes)\")\n",
    "    print(\"   â€¢ Total effects model captures the complete causal story\")\n",
    "else:\n",
    "    print(\"   â€¢ Both fundamental factors AND biomarkers have direct causal effects\")\n",
    "    print(\"   â€¢ Multiple pathways contribute to cognitive decline\")\n",
    "    print(\"   â€¢ Biomarker interventions could provide additional benefit\")\n",
    "\n",
    "print(f\"\\n2. INTERVENTION PRIORITIES:\")\n",
    "if best_model_name == 'M1_Total':\n",
    "    print(\"   â€¢ Education policy: Strongest modifiable factor\")\n",
    "    print(\"   â€¢ Early intervention: Age effects are cumulative\")\n",
    "    print(\"   â€¢ Genetic counseling: APOE4 carriers need enhanced care\")\n",
    "else:\n",
    "    print(\"   â€¢ Drug development: Target amyloid AND tau pathology\")\n",
    "    print(\"   â€¢ Combination therapy: Multiple pathways require multiple interventions\")\n",
    "    print(\"   â€¢ Precision medicine: Biomarker-guided treatment selection\")\n",
    "\n",
    "print(f\"\\n3. UNCERTAINTY & LIMITATIONS:\")\n",
    "print(\"   â€¢ All estimates have uncertainty - avoid overconfident claims\")\n",
    "print(\"   â€¢ Causal assumptions encoded in our DAG - alternative stories possible\")\n",
    "print(\"   â€¢ Observational data - randomized trials needed for definitive causation\")\n",
    "\n",
    "print(f\"\\n4. FUTURE RESEARCH:\")\n",
    "print(\"   â€¢ Test biomarker interventions in randomized trials\")\n",
    "print(\"   â€¢ Longitudinal data to validate causal pathways\")\n",
    "print(\"   â€¢ Genetic studies to refine APOE4 effect estimates\")\n",
    "\n",
    "# McElreath's model comparison insight\n",
    "print(f\"\\n MODEL COMPARISON INSIGHT:\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "if best_model_name == 'M1_Total':\n",
    "    print(\"The Total Effects model was preferred, suggesting:\")\n",
    "    print(\"â€¢ Biomarkers primarily mediate fundamental causes\")\n",
    "    print(\"â€¢ Age/Education/APOE4 capture most predictive information\")\n",
    "    print(\"â€¢ Parsimonious explanation: fewer parameters, same predictive power\")\n",
    "else:\n",
    "    print(\"The Direct Effects model was preferred, suggesting:\")\n",
    "    print(\"â€¢ Biomarkers have independent causal effects beyond mediation\")\n",
    "    print(\"â€¢ Multiple causal pathways operate simultaneously\")\n",
    "    print(\"â€¢ Complex biological systems require complex models\")\n",
    "\n",
    "# Final McElreath wisdom\n",
    "print(f\"\\n MCELREATH'S WISDOM:\")\n",
    "print(\"-\" * 25)\n",
    "print(\"'Models are not true or false, but more or less useful.'\")\n",
    "print(\"'The goal is not to find the true model, but to understand causation.'\")\n",
    "print(\"'Every model embodies assumptions - make yours explicit.'\")\n",
    "print(\"'Use models to think, not to replace thinking.'\")\n",
    "\n",
    "print(f\"\\n ALZHEIMER'S CAUSAL ANALYSIS COMPLETE!\")\n",
    "print(\" Following McElreath's methodology from assumptions to conclusions\")\n",
    "print(\" Ready for scientific communication and policy application\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Summary: McElreath's Methodology Applied\n",
    "\n",
    "This notebook demonstrates a **complete implementation** of Richard McElreath's Statistical Rethinking methodology using the `bayes_ordinal` package for Alzheimer's disease research.\n",
    "\n",
    "###  **McElreath's Workflow Completed:**\n",
    "\n",
    "1. ** Data Story** - Understanding how cognitive decline data arises\n",
    "2. ** Causal DAG** - Explicit assumptions about biological relationships  \n",
    "3. ** Confound Analysis** - Identifying what to control (and what NOT to)\n",
    "4. ** Statistical Models** - Translating causality into mathematics\n",
    "5. ** Prior Predictive** - Checking assumptions before seeing data\n",
    "6. ** Model Fitting** - Robust MCMC with comprehensive diagnostics\n",
    "7. ** Posterior Validation** - Never trust an unchecked model\n",
    "8. ** Counterfactual Reasoning** - Simulating interventions for causal insight\n",
    "9. ** Causal Interpretation** - What it means for science and policy\n",
    "\n",
    "###  **Key McElreath Principles Demonstrated:**\n",
    "\n",
    "- **Causation over Correlation** - Models embody causal assumptions\n",
    "- **Simulation over Interpretation** - Generate predictions, don't just read coefficients  \n",
    "- **Uncertainty Acknowledgment** - All estimates have uncertainty\n",
    "- **Assumption Transparency** - DAGs make our beliefs explicit\n",
    "- **Model Comparison** - Compare models to understand what data tell you\n",
    "- **Robust Validation** - Check everything before concluding anything\n",
    "\n",
    "###  **Scientific Impact:**\n",
    "\n",
    "This approach transforms statistical analysis from **\"finding significant effects\"** to **\"understanding causal mechanisms and estimating intervention effects\"** - exactly what McElreath advocates for modern science.\n",
    "\n",
    "###  **Technical Achievement:**\n",
    "\n",
    "Successfully demonstrates that `bayes_ordinal` can implement the complete McElreath workflow for **ordinal causal inference** - a significant methodological contribution to the field.\n",
    "\n",
    "---\n",
    "\n",
    "> *\"The goal is not to replace scientific thinking with statistical computation, but to support scientific thinking with principled statistical methods.\"* - Richard McElreath\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Enhanced Hierarchical Modeling for Research Center Effects \n",
    "\n",
    "**Multilevel Framework:** *\"Account for research center variation in Alzheimer's progression and biomarker assessment\"*\n",
    "\n",
    "### Why Hierarchical Modeling for ADNI Data?\n",
    "\n",
    "**Real-world ADNI data has research center hierarchical structure:**\n",
    "- **Participants** are nested within **Research Centers/Sites**\n",
    "- **Research Centers** vary in:\n",
    "  - Assessment protocols and equipment calibration\n",
    "  - Population demographics and recruitment patterns\n",
    "  - Clinical expertise and diagnostic consistency\n",
    "  - Geographic regions and genetic backgrounds\n",
    "\n",
    "**Hierarchical structure affects:**\n",
    "1. **Center-level random effects** - Baseline cognitive assessment differences\n",
    "2. **Assessment consistency** - Measurement error varies by center\n",
    "3. **Population selection** - Centers recruit different patient populations\n",
    "4. **Biomarker calibration** - Equipment and lab differences between sites\n",
    "\n",
    "**Standard models miss:**\n",
    "- **Clustering effects** - Participants from same center are more similar\n",
    "- **Assessment heterogeneity** - Cognitive measures vary by center protocols\n",
    "- **Geographic patterns** - Regional differences in Alzheimer's progression\n",
    "- **Proper uncertainty** - Center-level variation affects confidence intervals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Implement Hierarchical ADNI Models with Research Center Effects\n",
    "\n",
    "def generate_adni_data_with_centers(base_data, n_centers=15, seed=42):\n",
    "    \"\"\"\n",
    "    Enhance ADNI data with realistic research center hierarchical structure\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    n_participants = len(base_data)\n",
    "    \n",
    "    print(\" ADDING RESEARCH CENTER STRUCTURE TO ADNI DATA\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Generate center assignments (some centers are larger)\n",
    "    center_sizes = np.random.dirichlet(np.ones(n_centers) * 2, 1)[0]\n",
    "    center_assignments = np.random.choice(n_centers, size=n_participants, p=center_sizes)\n",
    "    \n",
    "    # Research center characteristics\n",
    "    center_assessment_bias = np.random.normal(0, 0.3, n_centers)  # Assessment protocol differences\n",
    "    center_population_severity = np.random.normal(0, 0.4, n_centers)  # Population selection differences\n",
    "    center_biomarker_calibration = np.random.normal(0, 0.2, n_centers)  # Equipment calibration differences\n",
    "    center_expertise = np.random.normal(0, 0.25, n_centers)  # Clinical expertise differences\n",
    "    \n",
    "    # Geographic/regional effects\n",
    "    center_regions = np.random.choice(4, n_centers)  # 4 geographic regions\n",
    "    regional_effects = np.array([0.1, -0.1, 0.2, -0.05])  # Regional AD progression differences\n",
    "    \n",
    "    # Add center structure to data\n",
    "    enhanced_data = base_data.copy()\n",
    "    enhanced_data['center_id'] = center_assignments\n",
    "    enhanced_data['region_id'] = center_regions[center_assignments]\n",
    "    \n",
    "    # Center effects on biomarkers (measurement differences)\n",
    "    for i in range(len(enhanced_data)):\n",
    "        center = enhanced_data.loc[i, 'center_id']\n",
    "        region = enhanced_data.loc[i, 'region_id']\n",
    "        \n",
    "        # Center affects biomarker measurements (calibration differences)\n",
    "        enhanced_data.loc[i, 'amyloid'] += center_biomarker_calibration[center]\n",
    "        enhanced_data.loc[i, 'tau'] += center_biomarker_calibration[center] * 0.8\n",
    "        enhanced_data.loc[i, 'hippocampus'] += center_biomarker_calibration[center] * -0.6\n",
    "        \n",
    "        # Center affects population selection (different baseline severity)\n",
    "        enhanced_data.loc[i, 'baseline_severity'] = (\n",
    "            enhanced_data.loc[i, 'baseline_severity'] + \n",
    "            center_population_severity[center] + \n",
    "            regional_effects[region]\n",
    "        )\n",
    "        \n",
    "        # Center assessment bias affects cognitive outcome measurement\n",
    "        enhanced_data.loc[i, 'cognitive_decline_latent'] += center_assessment_bias[center]\n",
    "    \n",
    "    # Recompute ordinal cognitive outcome with center effects  \n",
    "    cognitive_cutpoints = [-1.5, -0.5, 0.5, 1.5]\n",
    "    enhanced_data['cognitive_decline'] = np.digitize(enhanced_data['cognitive_decline_latent'], cognitive_cutpoints)\n",
    "    enhanced_data['cognitive_decline'] = np.clip(enhanced_data['cognitive_decline'], 0, 4)\n",
    "    \n",
    "    print(f\" Added {n_centers} research centers to {n_participants:,} participants\")\n",
    "    \n",
    "    print(f\"\\nCenter participant distribution:\")\n",
    "    for c in range(n_centers):\n",
    "        count = (enhanced_data['center_id'] == c).sum()\n",
    "        pct = count / len(enhanced_data) * 100\n",
    "        print(f\"  Center {c+1:2d}: {count:3d} participants ({pct:4.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nRegional distribution:\")\n",
    "    region_names = ['Northeast', 'Southeast', 'Midwest', 'West']\n",
    "    for r in range(4):\n",
    "        count = (enhanced_data['region_id'] == r).sum()\n",
    "        pct = count / len(enhanced_data) * 100\n",
    "        print(f\"  {region_names[r]}: {count:3d} participants ({pct:4.1f}%)\")\n",
    "    \n",
    "    # Show hierarchical variation\n",
    "    print(f\"\\n Research Center Variation:\")\n",
    "    center_decline = enhanced_data.groupby('center_id')['cognitive_decline'].mean()\n",
    "    print(f\"  Cognitive decline across centers: mean={center_decline.mean():.2f}, std={center_decline.std():.2f}\")\n",
    "    \n",
    "    center_amyloid = enhanced_data.groupby('center_id')['amyloid'].mean()\n",
    "    print(f\"  Amyloid levels across centers: mean={center_amyloid.mean():.2f}, std={center_amyloid.std():.2f}\")\n",
    "    \n",
    "    regional_decline = enhanced_data.groupby('region_id')['cognitive_decline'].mean()\n",
    "    print(f\"  Regional cognitive decline: std={regional_decline.std():.2f}\")\n",
    "    \n",
    "    return enhanced_data\n",
    "\n",
    "def create_hierarchical_adni_models(data):\n",
    "    \"\"\"\n",
    "    Create hierarchical ADNI models using bayes_ordinal package\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n BUILDING HIERARCHICAL ADNI MODELS WITH BAYES_ORDINAL\")\n",
    "    print(\"=\" * 65)\n",
    "    \n",
    "    # Prepare data for hierarchical modeling\n",
    "    y = data['cognitive_decline'].values\n",
    "    X_total = data[['age_scaled', 'education_scaled', 'apoe4']].values\n",
    "    X_direct = data[['age_scaled', 'education_scaled', 'apoe4', 'amyloid', 'tau', 'hippocampus']].values\n",
    "    center_ids = data['center_id'].values\n",
    "    region_ids = data['region_id'].values\n",
    "    n_centers = len(data['center_id'].unique())\n",
    "    n_regions = len(data['region_id'].unique())\n",
    "    \n",
    "    print(f\"Data: {len(y)} participants, {n_centers} centers, {n_regions} regions\")\n",
    "    \n",
    "    # Model 1: Standard Total Effects (ignores clustering)\n",
    "    print(\"\\n M1: STANDARD TOTAL EFFECTS (ignores center clustering)\")\n",
    "    M1_standard_total = bo.cumulative_model(\n",
    "        data=data,\n",
    "        outcome='cognitive_decline',\n",
    "        predictors=['age_scaled', 'education_scaled', 'apoe4'],\n",
    "        link='logit',\n",
    "        name='adni_standard_total'\n",
    "    )\n",
    "    \n",
    "    M1_standard_total.set_priors({\n",
    "        'beta': {'mu': 0, 'sigma': [0.5, 0.5, 0.8]},\n",
    "        'cutpoints': {'sigma': 2}\n",
    "    })\n",
    "    \n",
    "    print(\" Standard total effects model\")\n",
    "    \n",
    "    # Model 2: Center Random Intercepts (Total Effects)\n",
    "    print(\"\\n M2: CENTER RANDOM INTERCEPTS (total effects with center clustering)\")\n",
    "    \n",
    "    with pm.Model() as M2_center_total:\n",
    "        pm_model = bo.models.cumulative.cumulative_model(\n",
    "            y=y,\n",
    "            X=X_total,\n",
    "            K=5,\n",
    "            link='logit',\n",
    "            group_idx=center_ids,\n",
    "            n_groups=n_centers,\n",
    "            feature_names=['age_scaled', 'education_scaled', 'apoe4'],\n",
    "            model_name='adni_center_total'\n",
    "        )\n",
    "    \n",
    "    print(\" Center random intercepts model (total effects)\")\n",
    "    \n",
    "    # Model 3: Regional Effects + Center Random Intercepts\n",
    "    print(\"\\n M3: REGIONAL + CENTER EFFECTS (nested hierarchical structure)\")\n",
    "    \n",
    "    # Create regional interaction terms\n",
    "    regional_data = data.copy()\n",
    "    regional_interactions = []\n",
    "    for r in range(n_regions):\n",
    "        interaction_col = f'region_{r}'\n",
    "        regional_data[interaction_col] = (data['region_id'] == r).astype(int)\n",
    "        regional_interactions.append(interaction_col)\n",
    "    \n",
    "    M3_regional = bo.cumulative_model(\n",
    "        data=regional_data,\n",
    "        outcome='cognitive_decline',\n",
    "        predictors=['age_scaled', 'education_scaled', 'apoe4'] + regional_interactions,\n",
    "        link='logit',\n",
    "        name='adni_regional'\n",
    "    )\n",
    "    \n",
    "    # Hierarchical priors for regional effects\n",
    "    main_effects_sigma = [0.5, 0.5, 0.8]\n",
    "    regional_effects_sigma = [0.3] * n_regions\n",
    "    \n",
    "    M3_regional.set_priors({\n",
    "        'beta': {\n",
    "            'mu': 0,\n",
    "            'sigma': main_effects_sigma + regional_effects_sigma\n",
    "        },\n",
    "        'cutpoints': {'sigma': 2}\n",
    "    })\n",
    "    \n",
    "    print(\" Regional + center effects model\")\n",
    "    \n",
    "    # Model 4: Hierarchical Direct Effects (with biomarkers)\n",
    "    print(\"\\nðŸ§¬ M4: HIERARCHICAL DIRECT EFFECTS (biomarkers + center clustering)\")\n",
    "    \n",
    "    with pm.Model() as M4_center_direct:\n",
    "        pm_model = bo.models.cumulative.cumulative_model(\n",
    "            y=y,\n",
    "            X=X_direct,\n",
    "            K=5,\n",
    "            link='logit',\n",
    "            group_idx=center_ids,\n",
    "            n_groups=n_centers,\n",
    "            feature_names=['age_scaled', 'education_scaled', 'apoe4', 'amyloid', 'tau', 'hippocampus'],\n",
    "            model_name='adni_center_direct'\n",
    "        )\n",
    "    \n",
    "    print(\" Hierarchical direct effects model\")\n",
    "    \n",
    "    # Model 5: Center-Specific Biomarker Effects (random slopes)\n",
    "    print(\"\\n M5: CENTER-SPECIFIC BIOMARKER EFFECTS (random slopes)\")\n",
    "    \n",
    "    # Create center-biomarker interaction terms (for computational efficiency, limit to top centers)\n",
    "    biomarker_center_data = data.copy()\n",
    "    center_biomarker_interactions = []\n",
    "    \n",
    "    top_centers = data['center_id'].value_counts().head(8).index  # Top 8 centers by size\n",
    "    for c in top_centers:\n",
    "        for biomarker in ['amyloid', 'tau', 'hippocampus']:\n",
    "            interaction_col = f'center_{c}_{biomarker}'\n",
    "            biomarker_center_data[interaction_col] = (\n",
    "                (data['center_id'] == c) * data[biomarker]\n",
    "            ).astype(float)\n",
    "            center_biomarker_interactions.append(interaction_col)\n",
    "    \n",
    "    M5_center_slopes = bo.cumulative_model(\n",
    "        data=biomarker_center_data,\n",
    "        outcome='cognitive_decline',\n",
    "        predictors=['age_scaled', 'education_scaled', 'apoe4', 'amyloid', 'tau', 'hippocampus'] + center_biomarker_interactions,\n",
    "        link='logit',\n",
    "        name='adni_center_slopes'\n",
    "    )\n",
    "    \n",
    "    # Hierarchical priors for random slopes\n",
    "    biomarker_main_sigma = [0.5, 0.5, 0.8, 0.6, 0.6, 0.6]\n",
    "    center_slope_sigma = [0.2] * len(center_biomarker_interactions)\n",
    "    \n",
    "    M5_center_slopes.set_priors({\n",
    "        'beta': {\n",
    "            'mu': 0,\n",
    "            'sigma': biomarker_main_sigma + center_slope_sigma\n",
    "        },\n",
    "        'cutpoints': {'sigma': 2}\n",
    "    })\n",
    "    \n",
    "    print(\" Center-specific biomarker effects model\")\n",
    "    \n",
    "    models_dict = {\n",
    "        'M1_StandardTotal': M1_standard_total,\n",
    "        'M2_CenterTotal': M2_center_total,\n",
    "        'M3_RegionalEffects': M3_regional,\n",
    "        'M4_CenterDirect': M4_center_direct,\n",
    "        'M5_CenterSlopes': M5_center_slopes\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n HIERARCHICAL ADNI MODEL COMPARISON:\")\n",
    "    print(f\"=\" * 50)\n",
    "    print(f\"  M1: Standard total effects (independence)\")\n",
    "    print(f\"  M2: Center random intercepts (total effects)\")\n",
    "    print(f\"  M3: Regional + center effects (nested structure)\")\n",
    "    print(f\"  M4: Hierarchical direct effects (biomarkers + centers)\")\n",
    "    print(f\"  M5: Center-specific biomarker effects (random slopes)\")\n",
    "    print(f\"\\n Expected Results:\")\n",
    "    print(f\"  - M2 should improve fit over M1 (center clustering)\")\n",
    "    print(f\"  - M3 should capture regional AD variation\")\n",
    "    print(f\"  - M4 should show improved biomarker effects with clustering\")\n",
    "    print(f\"  - M5 should reveal center heterogeneity in biomarker relationships\")\n",
    "    print(f\"  - Hierarchical models provide realistic uncertainty for multi-site studies\")\n",
    "    \n",
    "    return models_dict, regional_data, biomarker_center_data\n",
    "\n",
    "# Generate enhanced ADNI data with research center structure\n",
    "print(\" STEP 11: HIERARCHICAL MODELING FOR RESEARCH CENTER VARIATION\")\n",
    "print(\"=\" * 75)\n",
    "\n",
    "adni_data_centers = generate_adni_data_with_centers(data, n_centers=15)\n",
    "adni_hierarchical_models, regional_data, biomarker_center_data = create_hierarchical_adni_models(adni_data_centers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}